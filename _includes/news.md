## News ðŸ“¢

- **[October. 2025]** We present an in-depth study of Agentic RL in [**Demystify Reinforcement Learning for Agentic Reasoning**](https://arxiv.org/abs/2510.11701)  and release the training and evaluation code [![](https://img.shields.io/github/stars/Gen-Verse/Open-AgentRL?style=social)](https://github.com/Gen-Verse/Open-AgentRL)! 
- **[February. 2025]** We propose [**ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates**](https://arxiv.org/abs/2502.06772) and release the training and inference code [![](https://img.shields.io/github/stars/Gen-Verse/ReasonFlux?style=social)](https://github.com/Gen-Verse/ReasonFlux)!
- **[January. 2025]** Our paper [**SuperCorrect: Supervising and Correcting Language Models with Error-Driven Insights**](https://arxiv.org/abs/2410.09008) is accepted by **ICLR 2025 !** ðŸŽ‰ðŸŽ‰ðŸŽ‰
- **[January. 2025]** Our paper [**Spatio-Temporal Energy-Guided Diffusion Model for Zero-Shot Video Synthesis and Editing**](https://ieeexplore.ieee.org/document/10845865) is accepted by **TCSVT !** ðŸŽ‰ðŸŽ‰ðŸŽ‰
- **[October. 2024]** The evaluation code and weights of **[SuperCorrect](https://arxiv.org/abs/2410.09008)**  [![](https://img.shields.io/github/stars/YangLing0818/SuperCorrect-llm?style=social)](https://github.com/YangLing0818/SuperCorrect-llm)has been released !
- **[September. 2024]**  Three papers  "**[BoT](https://arxiv.org/abs/2406.04271)**", "**[RealCompo](https://arxiv.org/abs/2402.12908)**", "**[VideoTetris](https://arxiv.org/abs/2406.04277)**" are accepted by **NeurIPS 2024 !**  ðŸŽ‰ðŸŽ‰ðŸŽ‰
- **[June. 2024]** Code and evaluation scripts of [**BoT**](https://github.com/YangLing0818/buffer-of-thought-llm/)  [![](https://img.shields.io/github/stars/YangLing0818/buffer-of-thought-llm?style=social)](https://github.com/YangLing0818/buffer-of-thought-llm) are released !
- **[June. 2024]** Training scripts and inference code of [**VideoTetris**](https://github.com/YangLing0818/VideoTetris/)  [![](https://img.shields.io/github/stars/YangLing0818/VideoTetris?style=social)](https://github.com/YangLing0818/VideoTetris) are released!
- **[May.2024]** Our paper "**[Mastering text-to-image diffusion: Recaptioning, planning, and generating with multimodal llms](https://arxiv.org/abs/2401.11708)**" is accepted by **ICML 2024** ! ðŸŽ‰ðŸŽ‰ðŸŽ‰
- **[March. 2024]** Inference code of  [**RPG**](https://github.com/YangLing0818/RPG-DiffusionMaster)  [![](https://img.shields.io/github/stars/YangLing0818/RPG-DiffusionMaster?style=social)](https://github.com/YangLing0818/RPG-DiffusionMaster) are released!.
- **[March. 2024]** Inference code of  [**RealCompo**](https://github.com/YangLing0818/RealCompo)  [![](https://img.shields.io/github/stars/YangLing0818/RealCompo?style=social)](https://github.com/YangLing0818/RealCompo) are released!.
- **[January. 2024]** Our paper **"[Cross-modal contextualized diffusion models for text-guided visual generation and editing](https://arxiv.org/abs/2402.16627)"**  is accepted by **ICLR 2024** ! ðŸŽ‰ðŸŽ‰ðŸŽ‰
